# DO NOT EDIT THIS FILE!
#
# This file is generated from the CDP specification. If you need to make
# changes, edit the generator and regenerate all of the modules.
#
# Specification verion: 1.3
#
#
# CDP domain: Tracing

from __future__ import annotations

import enum
import typing
from dataclasses import dataclass, field

from . import io
from .util import event_type


if typing.TYPE_CHECKING:
    from collections.abc import Generator

    from .util import T_JSON_DICT


# ruff: noqa: FURB189


class MemoryDumpConfig(dict):
    """
    Configuration for memory dump. Used only when "memory-infra" category is enabled.
    """

    def to_json(self) -> dict:
        return self

    @classmethod
    def from_json(cls, json: dict) -> MemoryDumpConfig:
        return cls(json)

    @classmethod
    def from_json_optional(cls, json: dict | None) -> MemoryDumpConfig | None:
        if json is None:
            return None
        return cls.from_json(json)

    def __repr__(self) -> str:
        return f'MemoryDumpConfig({super().__repr__()})'


@dataclass
class TraceConfig:
    #: Controls how the trace buffer stores data. The default is ``recordUntilFull``.
    record_mode: str | None = None

    #: Size of the trace buffer in kilobytes. If not specified or zero is passed, a default value
    #: of 200 MB would be used.
    trace_buffer_size_in_kb: float | None = None

    #: Turns on JavaScript stack sampling.
    enable_sampling: bool | None = None

    #: Turns on system tracing.
    enable_systrace: bool | None = None

    #: Turns on argument filter.
    enable_argument_filter: bool | None = None

    #: Included category filters.
    included_categories: list[str] = field(default_factory=list)

    #: Excluded category filters.
    excluded_categories: list[str] = field(default_factory=list)

    #: Configuration to synthesize the delays in tracing.
    synthetic_delays: list[str] = field(default_factory=list)

    #: Configuration for memory dump triggers. Used only when "memory-infra" category is enabled.
    memory_dump_config: MemoryDumpConfig | None = None

    def to_json(self) -> T_JSON_DICT:
        json: T_JSON_DICT = {}
        if self.record_mode is not None:
            json['recordMode'] = self.record_mode
        if self.trace_buffer_size_in_kb is not None:
            json['traceBufferSizeInKb'] = self.trace_buffer_size_in_kb
        if self.enable_sampling is not None:
            json['enableSampling'] = self.enable_sampling
        if self.enable_systrace is not None:
            json['enableSystrace'] = self.enable_systrace
        if self.enable_argument_filter is not None:
            json['enableArgumentFilter'] = self.enable_argument_filter
        if self.included_categories is not None:
            json['includedCategories'] = self.included_categories
        if self.excluded_categories is not None:
            json['excludedCategories'] = self.excluded_categories
        if self.synthetic_delays is not None:
            json['syntheticDelays'] = self.synthetic_delays
        if self.memory_dump_config is not None:
            json['memoryDumpConfig'] = self.memory_dump_config.to_json()
        return json

    @classmethod
    def from_json(cls, json: T_JSON_DICT) -> TraceConfig:
        return cls(
            record_mode=None if json.get('recordMode') is None else str(json['recordMode']),
            trace_buffer_size_in_kb=None
            if json.get('traceBufferSizeInKb') is None
            else float(json['traceBufferSizeInKb']),
            enable_sampling=None if json.get('enableSampling') is None else bool(json['enableSampling']),
            enable_systrace=None if json.get('enableSystrace') is None else bool(json['enableSystrace']),
            enable_argument_filter=None
            if json.get('enableArgumentFilter') is None
            else bool(json['enableArgumentFilter']),
            included_categories=[str(i) for i in json.get('includedCategories', [])],
            excluded_categories=[str(i) for i in json.get('excludedCategories', [])],
            synthetic_delays=[str(i) for i in json.get('syntheticDelays', [])],
            memory_dump_config=MemoryDumpConfig.from_json_optional(json.get('memoryDumpConfig')),
        )

    @classmethod
    def from_json_optional(cls, json: T_JSON_DICT | None) -> TraceConfig | None:
        if json is None:
            return None
        return cls.from_json(json)


class StreamFormat(enum.Enum):
    """
    Data format of a trace. Can be either the legacy JSON format or the
    protocol buffer format. Note that the JSON format will be deprecated soon.
    """

    JSON = 'json'
    PROTO = 'proto'

    def to_json(self) -> str:
        return self.value

    @classmethod
    def from_json(cls, json: str) -> StreamFormat:
        return cls(json)

    @classmethod
    def from_json_optional(cls, json: str | None) -> StreamFormat | None:
        if json is None:
            return None
        return cls.from_json(json)


class StreamCompression(enum.Enum):
    """
    Compression type to use for traces returned via streams.
    """

    NONE = 'none'
    GZIP = 'gzip'

    def to_json(self) -> str:
        return self.value

    @classmethod
    def from_json(cls, json: str) -> StreamCompression:
        return cls(json)

    @classmethod
    def from_json_optional(cls, json: str | None) -> StreamCompression | None:
        if json is None:
            return None
        return cls.from_json(json)


class MemoryDumpLevelOfDetail(enum.Enum):
    """
    Details exposed when memory request explicitly declared.
    Keep consistent with memory_dump_request_args.h and
    memory_instrumentation.mojom
    """

    BACKGROUND = 'background'
    LIGHT = 'light'
    DETAILED = 'detailed'

    def to_json(self) -> str:
        return self.value

    @classmethod
    def from_json(cls, json: str) -> MemoryDumpLevelOfDetail:
        return cls(json)

    @classmethod
    def from_json_optional(cls, json: str | None) -> MemoryDumpLevelOfDetail | None:
        if json is None:
            return None
        return cls.from_json(json)


class TracingBackend(enum.Enum):
    """
    Backend type to use for tracing. ``chrome`` uses the Chrome-integrated
    tracing service and is supported on all platforms. ``system`` is only
    supported on Chrome OS and uses the Perfetto system tracing service.
    ``auto`` chooses ``system`` when the perfettoConfig provided to Tracing.start
    specifies at least one non-Chrome data source; otherwise uses ``chrome``.
    """

    AUTO = 'auto'
    CHROME = 'chrome'
    SYSTEM = 'system'

    def to_json(self) -> str:
        return self.value

    @classmethod
    def from_json(cls, json: str) -> TracingBackend:
        return cls(json)

    @classmethod
    def from_json_optional(cls, json: str | None) -> TracingBackend | None:
        if json is None:
            return None
        return cls.from_json(json)


def end() -> Generator[T_JSON_DICT, T_JSON_DICT]:
    """
    Stop trace events collection.
    :returns: A generator
    :rtype: Generator[T_JSON_DICT, T_JSON_DICT]
    """

    cmd_dict: T_JSON_DICT = {
        'method': 'Tracing.end',
    }
    json = yield cmd_dict


def get_categories() -> Generator[T_JSON_DICT, T_JSON_DICT, list[str]]:
    """
    Gets supported tracing categories.

    **EXPERIMENTAL**

    :returns: A generator
    :rtype: Generator[T_JSON_DICT, T_JSON_DICT, list[str]]
    """

    cmd_dict: T_JSON_DICT = {
        'method': 'Tracing.getCategories',
    }
    json = yield cmd_dict
    return [str(i) for i in json.get('categories', [])]


def record_clock_sync_marker(
    sync_id: str,
) -> Generator[T_JSON_DICT, T_JSON_DICT]:
    """
    Record a clock sync marker in the trace.

    **EXPERIMENTAL**

    :param sync_id: The ID of this clock sync marker
    :returns: A generator
    :rtype: Generator[T_JSON_DICT, T_JSON_DICT]
    """

    params: T_JSON_DICT = {}
    params['syncId'] = sync_id
    cmd_dict: T_JSON_DICT = {
        'method': 'Tracing.recordClockSyncMarker',
        'params': params,
    }
    json = yield cmd_dict


def request_memory_dump(
    *,
    deterministic: bool | None = None,
    level_of_detail: MemoryDumpLevelOfDetail | None = None,
) -> Generator[T_JSON_DICT, T_JSON_DICT, tuple[str, bool]]:
    """
    Request a global memory dump.

    **EXPERIMENTAL**

    :param deterministic: *(Optional)* Enables more deterministic results by forcing garbage collection
    :param level_of_detail: *(Optional)* Specifies level of details in memory dump. Defaults to "detailed".
    :returns: A generator
    :rtype: Generator[T_JSON_DICT, T_JSON_DICT, tuple[str, bool]]
    """

    params: T_JSON_DICT = {}
    if deterministic is not None:
        params['deterministic'] = deterministic
    if level_of_detail is not None:
        params['levelOfDetail'] = level_of_detail.to_json()
    cmd_dict: T_JSON_DICT = {
        'method': 'Tracing.requestMemoryDump',
        'params': params,
    }
    json = yield cmd_dict
    return (str(json['dumpGuid']), bool(json['success']))


def start(
    *,
    categories: str | None = None,
    options: str | None = None,
    buffer_usage_reporting_interval: float | None = None,
    transfer_mode: str | None = None,
    stream_format: StreamFormat | None = None,
    stream_compression: StreamCompression | None = None,
    trace_config: TraceConfig | None = None,
    perfetto_config: str | None = None,
    tracing_backend: TracingBackend | None = None,
) -> Generator[T_JSON_DICT, T_JSON_DICT]:
    """
    Start trace events collection.

    :param categories: **(DEPRECATED)** **(EXPERIMENTAL)** *(Optional)* Category/tag filter
    :param options: **(DEPRECATED)** **(EXPERIMENTAL)** *(Optional)* Tracing options
    :param buffer_usage_reporting_interval: **(EXPERIMENTAL)** *(Optional)* If set, the agent will issue bufferUsage events at this interval, specified in milliseconds
    :param transfer_mode: *(Optional)* Whether to report trace events as series of dataCollected events or to save trace to a stream (defaults to ```ReportEvents````).
    :param stream_format: *(Optional)* Trace data format to use. This only applies when using ````ReturnAsStream```` transfer mode (defaults to ````json````).
    :param stream_compression: **(EXPERIMENTAL)** *(Optional)* Compression format to use. This only applies when using ````ReturnAsStream```` transfer mode (defaults to ````none````)
    :param trace_config: *(Optional)*
    :param perfetto_config: **(EXPERIMENTAL)** *(Optional)* Base64-encoded serialized perfetto.protos.TraceConfig protobuf message When specified, the parameters ````categories````, ````options````, ````traceConfig```` are ignored. (Encoded as a base64 string when passed over JSON)
    :param tracing_backend: **(EXPERIMENTAL)** *(Optional)* Backend type (defaults to ````auto```)
    :returns: A generator
    :rtype: Generator[T_JSON_DICT, T_JSON_DICT]
    """

    params: T_JSON_DICT = {}
    if categories is not None:
        params['categories'] = categories
    if options is not None:
        params['options'] = options
    if buffer_usage_reporting_interval is not None:
        params['bufferUsageReportingInterval'] = buffer_usage_reporting_interval
    if transfer_mode is not None:
        params['transferMode'] = transfer_mode
    if stream_format is not None:
        params['streamFormat'] = stream_format.to_json()
    if stream_compression is not None:
        params['streamCompression'] = stream_compression.to_json()
    if trace_config is not None:
        params['traceConfig'] = trace_config.to_json()
    if perfetto_config is not None:
        params['perfettoConfig'] = perfetto_config
    if tracing_backend is not None:
        params['tracingBackend'] = tracing_backend.to_json()
    cmd_dict: T_JSON_DICT = {
        'method': 'Tracing.start',
        'params': params,
    }
    json = yield cmd_dict


@event_type('Tracing.bufferUsage')
@dataclass
class BufferUsage:
    """
    **EXPERIMENTAL**


    """

    #: A number in range [0..1] that indicates the used size of event buffer as a fraction of its
    #: total size.
    percent_full: float | None
    #: An approximate number of events in the trace log.
    event_count: float | None
    #: A number in range [0..1] that indicates the used size of event buffer as a fraction of its
    #: total size.
    value: float | None

    @classmethod
    def from_json(cls, json: T_JSON_DICT) -> BufferUsage:
        return cls(
            percent_full=None if json.get('percentFull') is None else float(json['percentFull']),
            event_count=None if json.get('eventCount') is None else float(json['eventCount']),
            value=None if json.get('value') is None else float(json['value']),
        )

    @classmethod
    def from_json_optional(cls, json: T_JSON_DICT | None) -> BufferUsage | None:
        if json is None:
            return None
        return cls.from_json(json)


@event_type('Tracing.dataCollected')
@dataclass
class DataCollected:
    """
    **EXPERIMENTAL**

    Contains a bucket of collected trace events. When tracing is stopped collected events will be
    sent as a sequence of dataCollected events followed by tracingComplete event.
    """

    value: list[dict]

    @classmethod
    def from_json(cls, json: T_JSON_DICT) -> DataCollected:
        return cls(value=[dict(i) for i in json.get('value', [])])

    @classmethod
    def from_json_optional(cls, json: T_JSON_DICT | None) -> DataCollected | None:
        if json is None:
            return None
        return cls.from_json(json)


@event_type('Tracing.tracingComplete')
@dataclass
class TracingComplete:
    """
    Signals that tracing is stopped and there is no trace buffers pending flush, all data were
    delivered via dataCollected events.
    """

    #: Indicates whether some trace data is known to have been lost, e.g. because the trace ring
    #: buffer wrapped around.
    data_loss_occurred: bool
    #: A handle of the stream that holds resulting trace data.
    stream: io.StreamHandle | None
    #: Trace data format of returned stream.
    trace_format: StreamFormat | None
    #: Compression format of returned stream.
    stream_compression: StreamCompression | None

    @classmethod
    def from_json(cls, json: T_JSON_DICT) -> TracingComplete:
        return cls(
            data_loss_occurred=bool(json['dataLossOccurred']),
            stream=io.StreamHandle.from_json_optional(json.get('stream')),
            trace_format=StreamFormat.from_json_optional(json.get('traceFormat')),
            stream_compression=StreamCompression.from_json_optional(json.get('streamCompression')),
        )

    @classmethod
    def from_json_optional(cls, json: T_JSON_DICT | None) -> TracingComplete | None:
        if json is None:
            return None
        return cls.from_json(json)
